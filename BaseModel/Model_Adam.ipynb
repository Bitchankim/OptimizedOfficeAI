{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamModel 클래스 역할 \n",
    "# 목적 : MlpModel 클래스를 상속받아 Adam 연산 과정을 지원합니다. \n",
    "class AdamModel(MlpModel):\n",
    "    print(\"AdamModel 호출\")\n",
    "    def __init__(self, model_name, dataset, hconfigs):\n",
    "        \n",
    "        # Adam 의 사용 여부 기본값은 False 처리 합니다. \n",
    "        # Adam 은 연산과정에서 다소 높은 처리량을 요구합니다. \n",
    "        self.use_adam = False \n",
    "        super(AdamModel, self).__init__(model_name, dataset, hconfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamModel.backprop_layer 의 역할 \n",
    "# 목적 : \n",
    "# MlpModel.backprop_layer 의 과정과 매우 흡사하나,\n",
    "# Adam 을 적용한 경우의 파라미터 업데이트 과정입니다. \n",
    "# G_y : G_output\n",
    "# hconfig : 은닉계층 정보\n",
    "# pm : 파라미터\n",
    "# aux : 역전파에 필요한 위한 보조지표\n",
    "def adam_backprop_layer(self, G_y, hconfig, pm, aux):\n",
    "    print(\"AdamModel.backprop_layer 호출\")\n",
    "    \n",
    "    # MlpModel.backprop_layer 의 과정과 같습니다. \n",
    "    x, y = aux\n",
    "    \n",
    "    # [마지막 은닉계층과 이전 은닉계층의 ∂L/∂Y (delta_{k+1}) 준비 - 2/2단계]\n",
    "    # 전체 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
    "    # 𝜑(h) : 은닉계층에서 비선형 활성화함수 relu가 사용되므로, 이에 따른 미분과정(phi)\n",
    "    # 2단계에서 구현하는 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
    "    if hconfig is not None : \n",
    "        G_y = G_y * relu_derv(y)\n",
    "    \n",
    "    # [출력계층과 마지막 은닉계층 사이의 파라미터 갱신 준비]\n",
    "    # 가중치 갱신에 필요한 수식 : ∂L/∂W (X^t * G)\n",
    "    # 가장 마지막 은닉 계층(x.transpose())의 행렬전환 \n",
    "    g_y_weight = x.transpose()\n",
    "    g_y_input = pm['w'].transpose()\n",
    "    \n",
    "    # 가중치 갱신 준비과정 : ∂L/∂W \n",
    "    # X^t * G\n",
    "    G_weight = np.matmul(g_y_weight, G_y)\n",
    "    \n",
    "    # 편향 갱신에 필요한 수식 : ∂L/∂B \n",
    "    # \\bold{G}\n",
    "    G_bias = np.sum(G_y, axis=0)\n",
    "    \n",
    "    # [마지막 은닉계층과 이전 은닉계층의 ∂L/∂Y (delta_k+1) 준비 - 1/2 단계]\n",
    "    # 업데이트가 되지 않은 가중치(g_y_input)가 필요 \n",
    "    G_input = np.matmul(G_y, g_y_input)\n",
    "    \n",
    "    # 파라미터를 업데이트 하는 과정은\n",
    "    # AdamModel 클래스 내의 update_param() 에서 진행합니다. \n",
    "    self.update_param(pm = pm, key = 'w', delta = G_weight)\n",
    "    self.update_param(pm = pm, key = 'b', delta = G_bias)\n",
    "\n",
    "    return G_input\n",
    "\n",
    "AdamModel.backprop_layer = adam_backprop_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamModel.update_param 의 역할 \n",
    "# 목적 : \n",
    "# use_adam 플래그 변수 값에 맞춰 self.eval_adam_delta() 동작\n",
    "# 매개변수 업데이트\n",
    "\n",
    "def adam_update_param(self, pm, key, delta):\n",
    "    print(\"AdamModel.update_param 호출\")\n",
    "    \n",
    "    if self.use_adam:\n",
    "        # 본 메서드의 매개변수는 self.eval_adam_delta() 에 그대로 할당합니다. \n",
    "        delta = self.eval_adam_delta(pm, key, delta)\n",
    "    \n",
    "    # Adam 연산 수식 일부를 반환받은 후 \n",
    "    # delta 값을 기반으로 파라미터 업데이트를 진행합니다. \n",
    "    pm[key] -= self.learning_rate * delta\n",
    "        \n",
    "AdamModel.update_param = adam_update_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamModel.eval_adam_delta 의 역할 \n",
    "# 목적 : \n",
    "# 아담 알고리즘의 수식을 파라미터에 맞게 적용 합니다. \n",
    "# w_{(ij)}^{(t+1)} = w^{(t)}_{ij} + \\frac{\\eta}{\\sqrt{\\hat{g}^{(t)}_{ij}+\\epsilon}}\\hat{v}_{ij}^{(t)}\n",
    "def adam_eval_adam_delta(self, pm, key, delta):\n",
    "    print(\"AdamModel.eval_adam_delta 호출\")\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999 \n",
    "    epsilon = 1.0e-8 \n",
    "\n",
    "    # vkey = 'vw' or 'vb' \n",
    "    # 파라미터 업데이트에 대한 v 키 값 생성 \n",
    "    \n",
    "    # gkey = 'gw' or 'gb'\n",
    "    # 파라미터 업데이트에 대한 g 키 값 생성\n",
    "    \n",
    "    # step = 'nw' or 'nb'\n",
    "    # 파라미터 업데이트에 대한 n 키 값 생성 (업데이트 횟수)\n",
    "    vkey, gkey, step = 'v' + key, 'g' + key, 'n' + key\n",
    "    \n",
    "    # 각 키와 값에 대한 초기화를 위해 \n",
    "    # pm 변수내에 vkey 가 없는지 확인 후 초기화 변수 생성 \n",
    "    if vkey not in pm:\n",
    "        \n",
    "        # Adam 내의 v,g 값은 가중치와 편향 shape 에 맞게 0 으로 초기화 \n",
    "        pm[vkey] = np.zeros(pm[key].shape) \n",
    "        pm[gkey] = np.zeros(pm[key].shape)\n",
    "        pm[step] = 0  # 이 값은 본 메서드의 동작 횟수 \n",
    "\n",
    "    # v_it^(t) \n",
    "    # v^{(t)}_{ij} = \\beta_1v_{ij}^{(t-1)} + (1-\\beta_1)(\\frac{\\partial L}{\\partial w_{ij}^{(t)}})\n",
    "    v = pm[vkey] = beta_1 * pm[vkey] + (1 - beta_1) * delta\n",
    "    \n",
    "    # g_it^(t)\n",
    "    # g^{(t)}_{ij} = \\beta_2 g_{ij}^{(t-1)} + (1-\\beta_2)(\\frac{\\partial L}{\\partial w_{ij}^{(t)}})^2\n",
    "    g = pm[gkey] = beta_2 * pm[gkey] + (1 - beta_2) * (delta * delta)\n",
    "    \n",
    "    pm[step] += 1\n",
    "\n",
    "    # \\hat{v}\n",
    "    # \\hat{v}_{ij}^{(t)} = \\frac{v_{ij}^{(t)}}{1-\\beta^{t}_1}\n",
    "    v = v / (1 - np.power(beta_1, pm[step]))\n",
    "\n",
    "    # \\hat{g}\n",
    "    # \\hat{g}_{ij}^{(t)} = \\frac{g_{ij}^{(t)}}{1-\\beta^{t}_2}\n",
    "    g = g / (1 - np.power(beta_2, pm[step]))\n",
    "\n",
    "    # 파라미터 업데이트 수식 일부\n",
    "    return v / (np.sqrt(g) + epsilon)\n",
    "\n",
    "\n",
    "AdamModel.eval_adam_delta = adam_eval_adam_delta"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
